---
title: Fraser et al 2018 QRPs in Ecology and Evolution
author: ''
date: '2018-05-15'
slug: fraser-et-al-2018-qrps-in-ecology-and-evolution
categories:
  - reading
tags:
  - research practice
  - QRP
  - publication bias
  - reproducibility
  - transparency
  - ecology
  - evolution
header:
  caption: ''
  image: ''
bibliography: ../../static/files/citations/posts_read.bib
---



<p><strong>Fraser, H. S., Parker, T. H., Nakagawa, S., Barnett, A., Fidler, F. (2018) Questionable Research Practices in Ecology and Evolution. doi: 10.17605/OSF.IO/AJYQG.</strong></p>
<p>“Transformation process” of science communication is susceptible to confusion and corruption, has triggered both reflection and meta-research in other disciplines.</p>
<p><em>Forstmeier et al [8]:</em></p>
<p>Individual research practice is embedded in a broader culture, and promoite conditions of publication bias and type 1 errors. ‘Questionable research practices’ are fostered under conditions of publication bias, inflating false postive rates in the literature.</p>
<p>Within Ecology and evolution research, there is a dearth of replications of existing research. Existing advice predominantly focuses on practices that individual researchers can implement. There is increasing initiatives at broader scales, at the journal level, for example, to improve reporting standards.</p>
<p>Psychology and Medicine have both properly documented the prevalence of QRPs. <span class="citation">(2018)</span> represents the first study to document the prevalence of QRPs in EcoEvo.</p>
<div id="what-are-qrps" class="section level2">
<h2>What are QRPs?</h2>
<ul>
<li><code>p-hacking</code>:</li>
</ul>
<blockquote>
<p>A set of activities: checking the statistical significance of results before deciding whether to collect more data; stopping data collection early because results reached statistical significance; deciding whether to exclude data points (e.g., outliers) only after checking the impact on statistical significance and not reporting the impact of the data exclusion; adjusting statistical models, for instance by including or excluding covariates based on the resulting strength of the main effect of interest; and rounding of a p value to meet a statistical significance threshold (e.g., presenting 0.053 as p &lt; .05).</p>
</blockquote>
<ul>
<li><code>cherry picking</code>:</li>
</ul>
<blockquote>
<p>includes failing to report dependent or response variables or relationships that did not reach statistical significance or other threshold and/or failing to report conditions or treatments that did not reach statistical significance or other threshold.</p>
</blockquote>
<ul>
<li><code>HARK-ing</code> (hypothesizing after results are known):</li>
</ul>
<blockquote>
<p>includes presenting ad hoc and/or unexpected findings as though they had been predicted all along [16]; and presenting exploratory work as though it was confirmatory hypothesis testing [17].</p>
</blockquote>
<p>–&gt; Jian: ideally, exploratory work should be published / presented as just that, and offer potential hypotheses / mechanisms explaining the findings that future researchers can test.</p>
</div>
<div id="publication-bias-publish-or-perish-culture" class="section level2">
<h2>Publication bias, publish-or-perish culture</h2>
<blockquote>
<p>Publication bias in this context refers to a bias towards publishing statistically significant, ‘positive’ results and not publishing statistically non-significant (‘negative’ or null results).</p>
</blockquote>
<p>It has been documented for decads in disciplines like psychology. Moreover, the increase in the proportion of statistiaclly significant results has been increasing over the last 25 years.</p>
<p>What is the relationship between QRP prevalence and publication bias + publish/perish culture? It is thought that these broader set of conditions may be impacting on the frequency with which researchers use QRPs (Agnoli) (Fidler).</p>
<p># Relevance to my research</p>
</div>
<div id="building-a-picture-of-the-different-levels-of-research" class="section level2">
<h2>Building a picture of the different levels of research</h2>
<p>Most research focused on the individual researcher - reference for this? No. I get this impression, too. But would be good to evaluate this claim by looking at the literature systematically.</p>
</div>
<div id="non-nhst-qrps" class="section level2">
<h2>Non-NHST QRPs</h2>
<ul>
<li>p-hacking: point about “adjusting statistical models (e.g. by including or excluding covariates based on resulting strength of the main effect of interest)”. This is presumably referencing GLMS / GAMs and other models where there are fit statistics with p-values, etc. What is a parallel offence for other sorts of models, e.g. causal models?</li>
</ul>
<div id="refs" class="references">
<div id="ref-Fraser:2018cl">
<p>Fraser, Hannah Stephanie, Timothy H Parker, Shinichi Nakagawa, A Barnett, and Fiona Fidler. 2018. “Questionable Research Practices in Ecology and Evolution,” March, 1–24. doi:<a href="https://doi.org/10.17605/OSF.IO/AJYQG">10.17605/OSF.IO/AJYQG</a>.</p>
</div>
</div>
</div>
